%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Supplementary}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%###############################
\subsection{Children characteristics} \label{sSA:characteristics}
%###############################
%
Table \ref{tab:characteristics} shows the detailed information of the sampled children. The referred table includes the variable used for the matching procedure, i.e. chronological age, while also additional variables thought to be relevant for our hypothesis. No other variables are included as no known additional comorbidities, beside their hearing impairment, are suspected. Additionally, notice the pure tone average (PTA) data was not collected for the NH children.
%
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|ccccccc|} 
		\hline
		& Gender & Chronological & Device length & Hearing & Etiology & \multicolumn{2}{c |}{PTA (dB.)} \\[0.5ex]
		\cline{7-8}
		Child & & age (y;m) & of use (y;m) & age (y;m) & & unaided & aided \\[0.5ex] 
		\hline\hline
		& \multicolumn{7}{l |}{ \textbf{HI/CI children} } \\
		\rowcolor{gray}
		1 & female & 05;07 & 05;00 & 05;00 & Genetic & 120 & 19 \\
		2 & male & 06;04 & 05;09 & 05;09 & CMV & 106 & 23 \\
		\rowcolor{gray}
		3 & male & 06;07 & 05;10 & 05;10 & Genetic & 114 & 35 \\
		4 & female & 06;10 & 06;00 & 06;00 & Unknown & 120 & 20 \\ 
		\rowcolor{gray}
		5 & female & 07;00 & 06;03 & 06;03 & CMV & 115 & 25 \\ 
		6 & male & 07;00 & 05;08 & 05;08 & Genetic & 93 & 32 \\
		\rowcolor{gray}
		7 & female & 07;00 & 06;08 & 06;08 & Genetic & 117 & 17 \\
		8 & female & 07;00 & 05;05 & 05;05 & Unknown & 112 & 42 \\
		\rowcolor{gray}
		9 & male & 07;00 & 05;05 & 05;05 & CMV & 120 & 15 \\ 
		10 & female & 07;01 & 05;11 & 05;11 & Genetic & 120 & 35 \\		
		\rowcolor{gray}
		11 & male & 07;01 & 05;07 & 05;07 & Genetic & 113 & 42 \\
		12 & male & 07;02 & 06;05 & 06;05 & Genetic & 120 & 37 \\
		\rowcolor{gray}
		13 & male & 07;08 & 06;10 & 06;10 & CMV & 114 & 27 \\
		14 & male & 07;09 & 06;02 & 06;02 & CMV & 120 & 35 \\
		\rowcolor{gray}
		15 & male & 08;07 & 07;10 & 07;10 & CMV & 120 & 33 \\
		16 & male & 08;08 & 09;09 & 09;09 & Genetic & 95 & 27 \\
		
		\hline
		
		& \multicolumn{7}{l |}{ \textbf{NH children} } \\	
		\rowcolor{gray}
		17 & female & 06;05 & n.a. & 06;05 & n.a. & n.a. & n.a.\\
		18 & female & 06;06 & n.a. & 06;06 & n.a. & n.a. & n.a.\\
		\rowcolor{gray}
		19 & female & 06;07 & n.a. & 06;07 & n.a. & n.a. & n.a.\\
		20 & female & 06;09 & n.a. & 06;09 & n.a. & n.a. & n.a.\\
		\rowcolor{gray}
		21 & female & 06;09 & n.a. & 06;09 & n.a. & n.a. & n.a. \\
		22 & male & 06;09 & n.a. & 06;09 & n.a. & n.a. & n.a.\\ 
		\rowcolor{gray}
		23 & male & 06;09 & n.a. & 06;09 & n.a. & n.a. & n.a.\\
		24 & male & 06;10 & n.a. & 06;10 & n.a. & n.a. & n.a.\\
		\rowcolor{gray}
		25 & female & 07;01 & n.a. & 07;01 & n.a. & n.a. & n.a.\\
		26 & male & 07;01 & n.a. & 07;01 & n.a. & n.a. & n.a.\\
		\rowcolor{gray}
		27 & male & 07;04 & n.a. & 07;04 & n.a. & n.a. & n.a.\\
		28 & female & 07;08 & n.a. & 07;08 & n.a. & n.a. & n.a.\\
		\rowcolor{gray}
		29 & male & 07;08 & n.a. & 07;08 & n.a. & n.a. & n.a.\\
		30 & female & 07;09 & n.a. & 07;09 & n.a. & n.a. & n.a.\\ 
		\rowcolor{gray}
		31 & female & 08;00 & n.a. & 08;00 & n.a. & n.a. & n.a.\\
		32 & female & 08;01 & n.a. & 08;01 & n.a. & n.a. & n.a.\\	 
		\hline
		\multicolumn{8}{l}{\footnotesize{(y;m) = (years;months)}} \\
		\multicolumn{8}{l}{\footnotesize{n.a. = not applicable / not available}} \\
	\end{tabular}
	\caption[Characteristics of selected children]{Characteristics of selected children.}
	\label{tab:characteristics}
\end{table}
%
%
%###############################
\newpage
\subsection{Experiment details}
%###############################
%
%-------------------------------
\subsubsection{Transcription task} \label{ssSA:transcription}
%-------------------------------
%
The setting for the transcription task comprised the following steps \citep{Boonen_et_al_2020, Boonen_et_al_2021}:
%
\begin{enumerate} %\itemsep1pt
	\item the listener took a seat in front of a computer screen, located at the campus' computer laboratory.
	%
	\item the listener opened Qualtrics \cite{Qualtrics_2005} and select the transcription task.
	%
	\item the listener read two set of instructions presented on the computer screen about:
	\begin{enumerate}
		\item \textit{how to perform the task},
		\item \textit{the aspects not considered for the task}.
	\end{enumerate}
	%
	\item the listener hear the stimuli through high quality headphones, set at a comfortable volume.
	%
	\item the listener wrote the orthographic transcriptions of the utterances, in a free text field in the software environment. 
	%
\end{enumerate}
%
%
%-------------------------------
\subsubsection{Entropy calculation} \label{ssSA:entropy} 
%-------------------------------
%
The outcome from the transcription task was obtained following a two step procedure \citep{Boonen_et_al_2021}. First, we aligned the participant's orthographic transcriptions, at the utterance level, in a column-like grid structure similar to the one presented in Table \ref{tab:align_example}. This step was repeated for every one of the $6400$ transcriptions. Lastly, we computed the entropy measure of the aligned transcriptions as in \citet{Shannon_1948}: 
%
\begin{equation} \label{eq:entropy}
	H = H(\pmb{p}) = \frac{-\sum_{i=1}^{n} p_{i} \cdot \log_{2}(p_{i})}{\log_{2}(N)}
\end{equation}
%
where $H$ is bounded in the unit interval $[0,1]$, $n$ denotes the number of word occurrences within each utterance, $p_{i}$ the probability of such word occurrence, and $N$ the total number of aligned transcriptions per utterance.
%
\begin{comment}
under DoE literature, the design corresponds to $32$ experimental units with $10$ replicates each, making a total of $320$ experimental runs. Moreover, we register $20$ duplicates (transcriptions) for each run, making a total of $6400$ transcriptions.
\end{comment}
%
\begin{table}[h!]
	\centering
	\begin{tabular}{| c | ccccc | } 
		\hline
		Transcription & \multicolumn{5}{c |}{Utterance} \\ [0.5ex]
		\cline{2-6}
		number & 1 & 2 & 3 & 4 & 5 \\ [0.5ex] 
		\hline\hline
		1 & de & jongen & ziet & een & kikker \\ 
		\rowcolor{gray}
		& the & boy & see & a & frog \\ 
		\hline
		2 & de & jongen & ziet & de & [X] \\
		\rowcolor{gray}
		& the & boy & sees & the & [X] \\ 
		\hline
		3 & de & jongen & zag & [B] & kokkin \\
		\rowcolor{gray}
		& the & boy & saw & [B] & cook \\ 
		\hline
		4 & de & jongen & zag & geen & kikkers \\
		\rowcolor{gray}
		& the & boy & saw & no & frogs \\ 
		\hline
		5 & de & hond & zoekt & een & [X] \\
		\rowcolor{gray}
		& the & dog & searches & a & [X] \\ 
		\hline\hline
		Entropy & $0$ & $0.3109$ & $0.6555$ & $0.8277$ & $1$ \\
		\hline
		\multicolumn{4}{l}{\footnotesize{[B] = blank space, [X] = unidentifiable word}}
	\end{tabular}
	\caption[Alignment and entropy calculation]{Alignment and entropy calculation. Extracted from \citet{Boonen_et_al_2021}, and slightly modified with illustrative purposes.}
	\label{tab:align_example}
\end{table}
%

Entropy was used as a quantification of (dis)agreement between listeners' transcriptions, i.e. utterances yielding a high degree of agreement between transcribers were considered highly intelligible, and therefore registered a lower entropy $\left( H \rightarrow 0 \right)$. In contrast, utterances yielding a low degree of agreement were considered as exhibiting low intelligibility, and therefore registered a higher entropy $\left( H \rightarrow 1 \right)$ \citep{Boonen_et_al_2021, Faes_et_al_2021}. 

To exemplify relevant scenarios for the procedure, we generate the entropy for utterances $2$, $4$ and $5$ present in Table \ref{tab:align_example}. To make the example easy to calculate, we assume our data consisted only of five transcriptions in total ($N=5$).

For the second utterance, we observe that four transcriptions identify it with the word \textit{jongen}, while the last with the word \textit{hond}. Therefore, we registered two word occurrences ($n=2$), with probabilities $\pmb{p} = (p_{1}, p_{2}) = (4/5, 1/5)$, and entropy measure equal to:
%
\begin{align*}
	H &= \frac{-\sum_{i=1}^{2} p_{i} \cdot \log_{2}(p_{i})}{\log_{2}(5)} \\
	%
	&= \frac{- \left[ 0.8 \log_{2}(0.8) + 0.2 \log_{2}(0.2) \right] }{\log_{2}(5)} \\
	%
	&\approx 0.3109
\end{align*} 
%
For the fourth utterance, we observe that two transcriptions identify it with the word \textit{een}, one with \textit{de}, one with \textit{geen}, and one with a blank space [B]. Notice the blank space was not expected in such position, therefore, it was considered as a different word occurrence. As a result, the scenario had four word occurrences ($n=4$), with probabilities $\pmb{p} = (p_{1}, p_{2}, p_{3}, p_{4}) = (2/5, 1/5, 1/5, 1/5)$, and entropy measure equal to:
%
\begin{align*}
	H &= \frac{-\sum_{i=1}^{4} p_{i} \cdot \log_{2}(p_{i})}{\log_{2}(5)} \\
	%
	&= \frac{- \left[ 0.4 \log_{2}(0.4) + 3 \cdot 0.2 \log_{2}(0.2) \right] }{\log_{2}(5)} \\
	%
	&\approx 0.8277
\end{align*} 
%
Finally, for the fifth utterance, we observe that all transcriptions identify it with different words. Notice that when a transcriber did not managed to identify (part of) the complete utterance, (s)he was instructed to write [X]  to replace it. However, if more than one transcriber used [X] for an unidentifiable word, each was considered as being different from one another. The latter is done to avoid the artificial reduction of the entropy measure, as [X] values already indicate the lack of intelligibility of the word. Therefore, for the fifth utterance we registered five word occurrences ($n=5$), with probabilities $\pmb{p} = (p_{1}, \dots, p_{5}) = (1/5, \dots, 1/5)$, and entropy measure equal to:
%
\begin{align*}
	H &= \frac{-\sum_{i=1}^{5} p_{i} \cdot \log_{2}(p_{i})}{\log_{2}(5)} \\
	%
	&= \frac{- 5 \cdot 0.2 \log_{2}(0.2) }{\log_{2}(5)} \\
	%
	&= 1
\end{align*} 
%
%
%###############################
\subsection{About speech intelligibility} \label{sSA:SI}
%###############################
%
As described in the introduction, intelligible speech can be defined as the extent to which the elements in an speaker's acoustic signal, e.g. phonemes or words, can be correctly recovered by a listener \citep{Kent_et_al_1989, Whitehill_et_al_2004, vanHeuven_2008, Freeman_et_al_2017}. More specifically, in the context of the transcription task, speech intelligibility can be inferred from the extent a set of transcribers can identify the word contained in an utterance \cite{Boonen_et_al_2021}.

Therefore in this paper, through the implementation of our proposed model, \textit{speech intelligibility} is interpreted as a latent trait of individuals (hypothetical construct), which underlies the probability of observing a set of entropy replicates; that in turns, describes the ability of transcribers to identify the words in an utterance. Henceforth, statements such \textit{`speech intelligibility is influenced by'} can be read as \textit{`the probability of observing a set of entropy replicates for each individual in the sample is influenced by'}. Similar interpretation can be extended to the (latent) \textit{true} entropy measures.

Despite this practical approach, we emphasize we did our best to ensure the construct validity of our study, by ensuring the transcription task was well understood and appropriately performed by the transcribers.

We then expect speech intelligibility, as measured by our model, to reflect the (general) intelligibility of speech possessed by individuals, but do not deal with general epistemological considerations on the connection between the two.
%
%
%###############################
\subsection{Causal framework details} \label{sSA:causal_details}
%###############################
%
In this section we make explicit some of the assumptions that guided our causal framework, and later, our statistical analysis.

For \textbf{\textit{hearing age}}, and its relevance in our research hypothesis, we describe how the variable is constructed and its inherent assumptions. 

\textit{Hearing age} is a composite variable constructed by combining the \textit{chronological age} for the NH group, and the \textit{device length of use} for the HI/CI group \citep{Faes_et_al_2021} (see Table \ref{tab:characteristics}). The variable tries to approximate the amount of time a child has been actively hearing and developing his(her) language. However, no short of evidence has been presented in favor of using others surrogate measures, like \textit{chronological age} \cite{Flipsen_et_al_2006, Habib_et_al_2010, Grandon_et_al_2020} or \textit{age at implantation} \cite{Niparko_et_al_2010, Boons_et_al_2012, Bruijnzeel_et_al_2016, Dettman_et_al_2016}. We argue that the feasibility of using any other proxy measure, largely depends on the assumed reliability of the surrogate to approximate the variable of interest. In that sense, although we recognize \textit{hearing age} is not a `perfect' proxy \cite{Faes_et_al_2021}, we argue is the most appropriate to test our hypothesis, based on the relevant literature review and its assumed reliability to capture children's language development (although the latter has not been tested). Moreover, the variable serve two additional purposes: (i) control for sampling bias (see section \ref{sSA:sampling_bias}), and (ii) de-confound the parameter estimates of \textit{hearing status} \cite{Cinelli_et_al_2021}.

Finally, it is important to highlight that for modeling purposes, using more than one of the aforementioned proxies in tandem is not recommended. It is apparent from the previous description, the three surrogate measures share high similarities in their data construction. This in turn, could cause problems in the modeling procedure, as including variables that provide ``similar information'' might lead to a problem known as multicollinearity, in which our estimates get biased and less precise \cite{Farrar_et_al_1967}, leading us to incorrect inferences and conclusions.
%
\begin{comment}
	for the NH group uses the child's \textit{age} (at recording), the method cannot use the same variable for the other two groups. This is due to the fact that \textit{age} is merely used as a proxy, for the amount of time a child has been developing his(her) language. In that sense, more appropriate variables to use under the HI/CI group would be e.g. the \textit{device length of use}, which approximates the ``hearing age'' of such children, or their \textit{vocabulary size}, which resembles their "lexical age" \citep{Faes_et_al_2021}. For this research, we consider the \textit{device length of use} as the simplest one to implement.
\end{comment}

Regarding \textbf{\textit{hearing status}}, it is clear that its inclusion directly corresponds with the main purpose of the current research endeavor. i.e. compare the levels of \textit{speech intelligibility} among NH and HI/CI children.

In the case of \textbf{\textit{pure tone average}}, beyond the empirical evidence, the variable was included for two additional reasons. First, given that previous modeling efforts did not capture the full hierarchy of variability, it is possible that the effects of PTA on \textit{speech intelligibility} has been largely overlooked. Although evidence seem to suggest the variable has no effect, it is also sensible to think that HI/CI children with severe hearing loss, as accounted by the variable, might develop their language at a slower rate. This is especially true, if we consider the signal provided by the cochlear implant is still degraded compared to the signal in normal hearing scenarios \cite{Drennan_et_al_2008}. Finally, as with \textit{hearing age}, the variable might be useful to de-confound the parameter estimates of \textit{hearing status} \cite{Cinelli_et_al_2021}.

For \textbf{\textit{etiology}}, although empirical evidence did not found any effect on speech intelligibility \cite{Boonen_et_al_2021}, it is possible that these has also been largely overlooked, due to the lack of control on the full hierarchy of variability, similar to the \textit{pure tone average} case. Moreover, as with its predecessors, the variable might also be useful to de-confound the parameter estimates of \textit{hearing status} \cite{Cinelli_et_al_2021}, assuming our DAG is appropriate.

Finally, it is important to highlight the reason for the absence of other variables, deemed relevant by the literature, in our causal hypothesis.

For the \textbf{\textit{type of cochlear implantation}}, i.e. bilateral or contralateral, the variable was not included because we did not expect it to be related to other variables in the DAG, i.e. the decision on receiving one or the other is solely based on the intelligibility outcome, no matter how it is measured. This in turn means that its inclusion/exclusion would not confound our estimates. Additionally, given that most of the children underwent through sequential bilateral implantation (eleven in total), we anticipated the effect of variable already permeates the sample, therefore, if we wanted to investigate its effect, a larger sample size would be required.

For the case of \textbf{\textit{additional disabilities}}, e.g. mental retardation or speech motor problems, there was no need to consider it, as no additional comorbidities were reported.

In the case of \textbf{\textit{environmental factors}}, such as communication modality, the current sample of HI/CI children were raised orally using monolingual Dutch, with a limited support of signs, a scenario similar to the NH group (see section \ref{sS:children}).

Last but not least, \textbf{\textit{gender}} was not included in our hypothesis, as no theoretical nor empirical evidence have been found on its effects \cite{Boonen_et_al_2021}.
%
%
%###############################
\subsection{Sampling bias} \label{sSA:sampling_bias}
%###############################
%
As it happens in most observational, and some experimental studies, ours can also be a potential victim of sampling bias. While stratifying on the selection variables can help to balance the samples, and even `correct' the estimates \cite{Cinelli_et_al_2021, Deffner_et_al_2022}, as we do here by controlling for \textit{hearing age}. Given the sample's selection and matching procedures, we cannot ensure the HI/CI nor the NH groups are representative of their respective populations. 

Nevertheless, we argue that by controlling for other relevant confounders, the qualitative results presented in this study holds. However, we cannot discard the presence of unobservable variables that could bias our results, and in that sense, inferences beyond this particular set of children must be taken with care.
%
%
%###############################
\subsection{Model details} \label{sSA:model_details}
%###############################
%
%-------------------------------
\subsubsection{Variability in the beta-proportion distribution} \label{ssSA:model_variability}
%-------------------------------
%
Figure \ref{fig:BetaProp} shows the implications of different `sample sizes' ($M_{i}$), on the dispersion of the beta-proportion distribution \cite{Kruschke_2015}. The panels show different ``average'' entropies: the middle panel assumes $\mu=0.5$, the left $\mu=0.2$, and the right $\mu=0.8$ (as shown by the discontinuous lines).

In all three panels we notice two prevalent pattern: (i) the higher the `sample size', the less dispersed is the distribution, and (ii) as expected from non-linear models, the behavior of the dispersion depends on the location of the distribution, i.e. their average value.

Concerning the first pattern, we expect that if the posterior estimates for $M_{i}$ reach lower values, it would imply the entropy replicates $H^{O}_{bik}$ had high dispersion. In contrast, higher $M_{i}$ estimates would imply a lower dispersion in the replicates. In this particular case, a good comparison point is the number of utterances/replicates. If $M_{i}<10$, it would imply that our effective `sample size' (measuring points) is less than the actual number of replicates, and therefore, we would need more replicates to provide an accurate measure of the (latent) \textit{true} entropy. In contrast, $M_{i}>10$ would imply the opposite, and no more measurements would be required. Notice here, we are inherently understanding the estimates for $M_{i}$ as a `reliability' score. More specifically, `reliability' is understood as the `number' of new entropy measures required to make us teeter between the new data and our prior belief about the average entropy $\mu$ \cite{Kruschke_2015}.

\begin{comment}
	The value we choose for the prior $\theta$ can be thought of this way: It is the number of new flips of the coin that we would need to make us teeter between the new data and the prior belief about $\mu$. If we would only need a few new flips to sway our beliefs, then our prior beliefs should be represented by a small $\theta$. If we would need a large number of new flips to sway us away from our prior beliefs about $\mu$, then our prior beliefs are worth a very large $\theta$ \cite{Kruschke_2015}.
\end{comment}

As a final point, it is important to highlight that the approach uses the `sample size' parameter to model the replicates' heterogeneity. The latter in turn, effectively estimates an entropy measurement error model \cite{Carroll_2006}.
%
\begin{figure} [!h]
	\centering
	\includegraphics[width=0.9\linewidth]{BetaProp_dist2.pdf}
	\caption[Variability in a beta-proportional distribution]{Variability in a beta-proportional distribution. Discontinuous lines describe the average value for the distribution ($\mu$), solid lines describe the distribution assuming different $\theta = M_{i}$.}
	\label{fig:BetaProp}
\end{figure}
%
%
%-------------------------------
\subsubsection{Data pre-processing} \label{ssSA:preprocessing}
%-------------------------------
%
Besides the exclusion of corrupted observations, e.g. no available transcription, no other information was excluded before the modeling process. This decision departs from what has been done in previous research \cite{Boonen_et_al_2020, vanDaal_2020, Boonen_et_al_2021}. The reason is that we believe the identification of influential observations, through preliminary or univariate procedures, might lead to erroneous exclusion of information, ultimately biasing our results. Furthermore, we believe the identification of \textit{outliers} should not be done outside the context of a full modeling effort \citep{McElreath_2020}, as what can behave as an \textit{outlier} based on a univariate analysis, might behave as expected under the appropriate model.

Considering the previous, instead of eliminating information based on other types of analysis, we proposed a set of models that were \textit{robust} against influential observations. Considering the flexibility of the Bayesian framework, the proposal of such models was a trivial task (see Table \ref{tab:models}).
%
%
%
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.6\linewidth]{prior_predictive.pdf}
	\caption[Prior distribution implications]{Prior distribution implications: speech intelligibility, \textit{true} entropy and observed entropy scales.}
	\label{fig:priors}
\end{figure}
%
%
%-------------------------------
\subsubsection{Priors and hyper-priors}
%-------------------------------
%
For all models, the selection of priors and hyper-priors was done through prior predictive simulation \citep{McElreath_2020}. The selected priors were considered mildly informative and regularizing. 

Figure \ref{fig:priors} shows the implication of our assumptions on the three outcome scales of interest: the \textit{speech intelligibility}, the \textit{true} entropy, and the \textit{observed} entropy replicates. Notice, no undesirable assumption has crept in any of the scales. Therefore, the estimates are free to visit a wide range of results, while also have a low probability of reaching impossible outcomes.

Hereby follows a description of the priors:
%
\begin{align}
	%
	M_{i} & \sim \text{Log-Normal}( \mu_{M}, \sigma_{M}) \\
	%
	a_{b} & \sim \text{Normal}(\mu_{b}, \sigma_{b}) \\
	%
	a_{i} & \sim \text{Normal}(\mu_{i}, \sigma_{i}) \\
	%
	\alpha & \sim \text{Normal}(0, 0.2) \\
	%
	\alpha_{E[i],HS[i]} & \sim \text{Normal}(0, 0.3) \\
	%
	\beta_{A, HS[i]} & \sim \text{Normal}(0 , 0.3) \\
	%
	\beta_{P, HS[i]} & \sim \text{Normal}(0, 0.3)
	%
\end{align}

while the hyper-priors were defined as follows:
%
\begin{align}
	%
	\mu_{M} & \sim \text{Normal}(0, 0.5) \\
	%
	\sigma_{M} & \sim \text{Exponential}(1) \\
	%
	\mu_{b} & \sim \text{Normal}(0, 0.2) \\
	%
	\sigma_{b} & \sim \text{Exponential}(1) \\
	%
	\mu_{i} & \sim \text{Normal}(0, 0.2) \\
	%
	\sigma_{i} & \sim \text{Exponential}(1)
	%
\end{align}
%
%
%-------------------------------
\subsubsection{Estimation procedure} \label{ssSA:model_estimation}
%-------------------------------
The proposed models in Table \ref{tab:models} were estimated under the Bayesian framework. More specifically, we used the No-U-Turn Hamiltonian Monte Carlo algorithm (No-U-Turn HMC) \citep{Betancourt_et_al_2013, Duane_et_al_1987, Hoffman_et_al_2014, Neal_2012} implemented in \texttt{Stan} \citep{Stan_2020}. Additionally, we used \texttt{R} \citep{R_2015} and its integration packages \citep{RStan_2020} to analyze its outputs.

\begin{comment}
	\footnote{see \citet{Rivera_2021} (p. 11-13, 15-27) for a detailed description of its benefits and shortcomings.}
\end{comment}
%
%
\begin{figure}[!h]
	\centering
	\includegraphics[trim=0 490 0 0, clip, width=0.7\textwidth]{power_result23.pdf}
	%trim=left lower right upper
	\caption[Group contrasts: Power on small effects]{Group contrasts: Power on small effects ($\approx 0.15$ differences between groups)}
	\label{fig:contrasts}
\end{figure}
%
%
%-------------------------------
\subsubsection{Simulation} \label{ssSA:model_simulation}
%-------------------------------
%
Prior to fitting real data, all the proposed models were tested on simulated data. The simulation was done with two purposes: (i) to test the models' ability to recover the `real' parameter values \cite{Fogarty_et_al_2022}, and (ii) to test the data size power on our assumed hypothesis \cite{Kruschke_2015}. 

On both instances, we used the \textit{equivalent prior sampling} method \cite{Winkler_1967}, informed by the appropriate children population \cite{DeRaeve_2016}. Moreover, we tested three goals\footnote{see \citet{Kruschke_2015} chapter 13 for a detailed overview of the method.}: (a) reject the null value of a parameter, (b) affirm a predicted value, and (c) achieve an estimate precision.

The results of our simulations indicated that each statistical model was able to recover the `real' parameters values, with a sample sizes similar to the population size.

Furthermore, the power analysis reported three key points. First, assuming a sample size similar to our data size ($16$ children per group) and medium differences among the groups ($\approx 0.4$), the hearing group contrasts manage to affirm the predicted values with power above the $80\%$ threshold. However, the same cannot be said if we assume small differences between the groups ($\approx 0.15$), where the power of the estimates barely surpass the $60\%$ threshold (see figure \ref{fig:contrasts}). Second, other parameters of interest ($bA$ and $bP$) affirm the predicted value with power above the $80\%$ threshold, even with small assumed effects ($0.15$ and $0.1$, respectively). Third and final, no parameter (nor any contrast) managed to reject the null hypothesis or achieve high estimates precision with power above the $80\%$ threshold.

As a result we can say, the probabilistic implementations work as intended, i.e. they manage to recover the appropriate estimate values, if enough sample size is available. Furthermore, with our current data size, if the contrast effects are small, we can be certain that $60\%$ of the time our models will affirm the correct value. However, the precision of our estimates will not allow us to make categorical inferences.


For more details on the assumed effects, as well as the simulation code, refer to the GitHub repository: \url{https://github.com/jriveraespejo/PhD_UA_paper1}
%
%
%-------------------------------
\subsubsection{Model selection} \label{ssSA:model_selection}
%-------------------------------
%
As stated in previous sections, the current research used the Information-Theoretic Approach \citep{Anderson_2008, Chamberlain_1965} for model selection. The application of the approach required: (i) the expression of the research hypothesis into statistical models, (ii) the selection of the most plausible models, and (iii) to produce inferences based on one or multiple selected models. Since the first step is covered in sections \ref{sS:causal_frame} and \ref{sS:stat_analysis}, and expanded in supplementary sections \ref{sSA:causal_details} and \ref{sSA:model_details}, here we proceed with the intermediate step. 

We used the widely applicable information criterion (WAIC) \citep{Watanabe_2013}, and the Pareto-smoothed importance sampling cross-validation (PSIS) \citep{Vehtari_et_al_2021} as the criteria to select among competing models. Two reasons justify our decision. First, both criteria allow us to use all the information of our Bayesian models, i.e. the posterior distribution of the parameters. Last, and more important, both criteria provide us with the best approximations for the out-of-sample (cross-validated) deviance \citep{McElreath_2020}. The deviance is the best approximation for the Kullback-Liebler (KL) divergence \citep{Kullback_et_al_1951}, i.e. a measure of how far a model is from describing the \textit{true} distribution of our data. In that sense, by comparing the deviance between competing models, we can measure which model is the farthest from \textit{perfect (predictive) accuracy} for our data \cite{McElreath_2020}.

Table \ref{tab:WAIC} and \ref{tab:PSIS} report the WAIC and PSIS criteria for all the proposed models, sorted by the appropriate statistic. Three patterns are visible from the two tables. 

First, we notice that around $63\%$ of the evidence (WE) support two types of models: (a) no interaction and one estimated ``sample size'', and (b) three ``similar'' interaction models with one estimated ``sample size''. Furthermore, $35\%$ of the evidence is condensed in the diverse type of \textit{robust} models, while the remaining $2\%$ is negligible dispersed in the remaining ones.

Second, comparing the differences in WAIC/PSIS from the ``best'' model (dWAIC and dPSIS, respectively), we arrive at the same conclusion as the previous paragraphs, i.e. the model with no interaction and one ``sample size'' is the best model, followed by the interaction models with one ``sample size'', and a bit further away, by the \textit{robust} models. One important point to highlight is that all these models are indistinguishable from each other, as it can be inferred from their precision estimate (dSE). However, we can also observe a ``bit more precise'' support for models with any type of interaction and one estimated ``sample size'', than for the \textit{robust} models.

Third, we observe a greater over-fitting penalty (pWAIC and pPSIS, respectively) for models with a fixed ``sample size'' than any other model. This is quite particular, as one would expect that a model with less parameters would over-fit less the data. However in this case, it implies the complexity of the data requires more parameters (than less), especially considering there are some highly influential observations that might sway the estimates of the less parameterized models (see section \ref{sS:results_outliers}). 

Considering all of the above, the final inferences will be performed with models three and ten. The former is considered because it is the highest supported model. The latter is considered because it encompasses the remaining highest supported models. Furthermore, no \textit{robust} model is analyzed, as we prefer a more parsimonious depiction of our hypothesis.
%
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|lcccccc|} 
		\hline
		Model & \multicolumn{1}{c}{Name} & WAIC & SE & dWAIC & dSE & pWAIC & WE \\[0.5ex] 
		\hline\hline
		\rowcolor{gray}
		3 & No interaction (one ``size'') & -621.0 & 42.99 & 0.0 & -- & 31.1 & 0.18 \\
		10 & Full interaction (one ``size'') & -621.0 & 42.98 & 0.1 & 0.78 & 31.2 & 0.18 \\
		\rowcolor{gray}
		9 & Etiology interaction (one ``size'') & -620.7 & 43.07 & 0.4 & 0.48 & 31.2 & 0.15 \\
		8 & Age interaction (one ``size'') & -620.2 & 42.91 & 0.8 & 0.76 & 32.1 & 0.12 \\
		\rowcolor{gray}
		11 & Age interaction (robust) & -620.1 & 42.70 & 0.9 & 2.21 & 34.2 & 0.12 \\
		12 & Etiology interaction (robust) & -619.9 & 42.77 & 1.1 & 2.06 & 34.4 & 0.10 \\
		\rowcolor{gray}
		4 & No interaction (robust) & -619.2 & 42.81 & 1.8 & 2.18 & 34.8 & 0.07 \\
		13 & Full interaction (robust) & -618.8 & 42.65 & 2.2 & 2.17 & 35.0 & 0.06 \\
		\rowcolor{gray}
		5 & Age interaction (fixed ``size'') & -578.2 & 52.51 & 42.8 & 16.85 & 50.7 & 0.00 \\
		6 & Etiology interaction (fixed ``size'') & -578.2 & 52.63 & 42.8 & 16.95 & 50.7 & 0.00 \\
		\rowcolor{gray}
		2 & No interaction (fixed ``size'') & -577.6 & 52.59 & 43.5 & 16.97 & 51.0 & 0.00 \\
		1 & Intercept only (fixed ``size'') & -576.8 & 52.98 & 44.3 & 17.40 & 51.8 & 0.00 \\
		\rowcolor{gray}
		7 & Full interaction (fixed ``size'') & -575.8 & 52.58 & 45.3 & 16.96 & 52.1 & 0.00 \\
		\hline\hline
		\multicolumn{1}{|r|}{\small SE} & \multicolumn{7}{l|}{\small WAIC approximate standard error} \\
		\multicolumn{1}{|r|}{\small dWAIC} & \multicolumn{7}{l|}{\small difference in WAIC from the best model} \\
		\multicolumn{1}{|r|}{\small dSE} & \multicolumn{7}{l|}{\small standard error for the difference in WAIC from the best model} \\
		\multicolumn{1}{|r|}{\small pWAIC} & \multicolumn{7}{l|}{\small WAIC over fitting penalty} \\
		\multicolumn{1}{|r|}{\small WE} & \multicolumn{7}{l|}{\small weight of evidence} \\
		\hline
	\end{tabular}
	\caption[Fit of statistical models: WAIC]{Fit of statistical models: WAIC.}
	\label{tab:WAIC}
\end{table}
%
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|lcccccc|} 
		\hline
		Model & \multicolumn{1}{c}{Name} & PSIS & SE & dPSIS & dSE & pPSIS & WE \\[0.5ex] 
		\hline\hline
		\rowcolor{gray}
		3 & No interaction (one ``size'') & -619.8 & 42.98 & 0.0 & -- & 31.8 & 0.22 \\
		10 & Full interaction (one ``size'') & -619.7 & 42.97 & 0.0 & 0.82 & 31.8 & 0.22 \\
		\rowcolor{gray}
		9 & Etiology interaction (one ``size'') & -619.2 & 43.05 & 0.5 & 0.51 & 32.0 & 0.17 \\
		8 & Age interaction (one ``size'') & -619.0 & 42.89 & 0.7 & 0.81 & 31.8 & 0.15 \\
		\rowcolor{gray}
		11 & Age interaction (robust) & -617.8 & 42.70 & 2.0 & 2.19 & 35.4 & 0.08 \\
		12 & Etiology interaction (robust) & -617.7 & 42.77 & 2.1 & 2.07 & 35.5 & 0.08 \\
		\rowcolor{gray}
		4 & No interaction (robust) & -616.5 & 42.81 & 3.3 & 2.19 & 36.1 & 0.04 \\
		13 & Full interaction (robust) & -616.3 & 42.64 & 3.4 & 2.13 & 36.2 & 0.04 \\
		\rowcolor{gray}
		6 & Etiology interaction (fixed ``size'') & -576.0 & 52.63 & 43.7 & 17.00 & 51.7 & 0.00 \\
		5 & Age interaction (fixed ``size'') & -575.9 & 52.54 & 43.9 & 16.94 & 51.9 & 0.00 \\
		\rowcolor{gray}
		2 & No interaction (fixed ``size'') & -575.3 & 52.59 & 44.4 & 17.03 & 52.1 & 0.00 \\
		1 & Intercept only (fixed ``size'') & -574.6 & 52.97 & 45.1 & 17.44 & 52.9 & 0.00 \\
		\rowcolor{gray}
		7 & Full interaction (fixed ``size'') & -573.8 & 52.61 & 46.0 & 17.01 & 53.1 & 0.00 \\
		\hline\hline
		\multicolumn{1}{|r|}{\small SE} & \multicolumn{7}{l|}{\small WAIC approximate standard error} \\
		\multicolumn{1}{|r|}{\small dPSIS} & \multicolumn{7}{l|}{\small difference in PSIS from the best model} \\
		\multicolumn{1}{|r|}{\small dSE} & \multicolumn{7}{l|}{\small standard error for the difference in PSIS from the best model} \\
		\multicolumn{1}{|r|}{\small pPSIS} & \multicolumn{7}{l|}{\small PSIS over fitting penalty} \\
		\multicolumn{1}{|r|}{\small WE} & \multicolumn{7}{l|}{\small weight of evidence} \\
		\hline
	\end{tabular}
	\caption[Fit of statistical models: PSIS]{Fit of statistical models: PSIS.}
	\label{tab:PSIS}
\end{table}
%
%