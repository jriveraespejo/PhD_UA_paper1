\section{Introduction}

Intelligible speech can be defined as the extent to which the elements in an speaker's acoustic signal, e.g. phonemes or words, can be correctly recovered by a listener \citep{Kent_et_al_1989, Whitehill_et_al_2004, vanHeuven_2008, Freeman_et_al_2017}. Because intelligible spoken language requires all core components of speech perception, cognitive processing, linguistic knowledge, and articulation to be mastered \citep{Freeman_et_al_2017}, its attainment carries an important societal value, as it is a milestone in children's language development, the ultimate checkpoint for the success of speech therapy, and has been qualified as the "gold standard for assessing the benefit of cochlear implantation" \citep{Chin_et_al_2012}. 

The literature suggest there are two perspectives from which speech intelligibility (SI) can be assessed: the speaker/message and listener's perspective \citep{Boonen_et_al_2020, Boonen_et_al_2021}. The first, also known as acoustic studies, center its focus on assessing separately particular characteristics of speech samples, e.g. their pitch, duration or stress (supra segmental characteristics), or the articulation of vowels and consonants (segmental characteristics) \citep{Rowe_et_al_2018}. Whereas the second, also known as perceptual studies, center its focus on making holistic assessments of the speech stimuli, e.g. measure their perceived quality \citep{Boonen_et_al_2020, Boonen_et_al_2021}. On both instances, the stimuli/representation (children's utterances) can be generated from reading at loud, contextualized utterances, or spontaneous speech tasks\footnote{ordered on increasing level of ecological validity \citep{Flipsen_2006,Ertmer_2011}}.

\begin{comment}
Based on their description, it seems that that perceptual studies are more subjective than acoustic studies, as they do not rely on "objective" measurements, i.e. time duration, wave amplitude, among others, available in the former. However, for the case of SI, there are objective and subjective assessment methodologies.
\end{comment}

Moreover, perceptual studies can use multiple approaches to measure SI. However, they can be largely grouped into two: objective and subjective ratings (OR and SR, respectively) \citep{Hustad_et_al_2020}. In OR, listeners transcribe children's utterances orthographically or phonetically, and use such information to construct an index of SI. In contrast, under SR, listeners directly produce the SI index using one or a combination of the following procedures: absolute holistic (HJ), analytic (AJ), or comparative (CJ) judgments, the last, also known as the relative holistic method. 

It is clear from the previous description, that under perceptual studies, OR methods are more valid\footnote{defined as the extent to which scores are appropriate for their intended interpretation and use \citep{Lesterhuis_2018, Trochim_2022}.} and reliable\footnote{the extend to which a measure would give us the same result over and over again \citep{Trochim_2022}, i.e. measure something free from error in a consistent way.} than SR methods, and therefore as their name imply, are usually used as an objective measure of SI \citep{Boonen_et_al_2021, Faes_et_al_2021}. However, given the demanding process in terms of number of listeners required, time, and ultimately cost entailed by OR methods, SR methods can be regarded as an efficient alternative, as long as we can ensure they provide equally valid and reliable SI measures.

Furthermore, within the SR methods, the literature evidence indicate that while HJ procedures are less time consuming than any other alternative \citep{Boonen_et_al_2021}, they suffer from a lack of intra- and inter-rater reliability\footnote{the lack of \textbf{intra-rater reliability} happens when the listener rates the same speech recording (representation) after a time lapse, and does not arrive at exactly the same score. On the other hand, the lack of \textbf{inter-rater reliability} happens if two listeners, who independently rate the same representation, does not arrive to the same score \citep{Trochim_2022}.} \citep{McLeod_et_al_2012, Johannisson_et_al_2014, Hustad_et_al_2020, Boonen_et_al_2021}. Additionally, the literature inform us the procedure does not allow to assess subtle differences in the representations \citep{Boonen_et_al_2021}, while the scales derived from them are usually coarse, where children reach the higher levels fairly quickly \citep{DeRaeve_2010}, e.g. the Speech Intelligibility Rating (SIR) \citep{Cox_et_al_1989, McDaniel_et_al_1992}.

In this context, CJ has received a growing attention, because it directly tackles the issues with the HJ procedures: it fosters reliable \citep{Verhavert_et_al_2019} and valid scores \citep{Bramley_2008, Lesterhuis_2018}, while the judges can focus only on the relevant aspects of the compared representations, i.e. the "just noticeable difference" \citep{Lesterhuis_2018}. Moreover, depending on the task, it provides a set of additional benefits, e.g. judges feel more comfortable using comparisons, which foster more accurate judgments \citep{Gill_et_al_2013}, it does not require a high level of expertise \citep{Lesterhuis_2018, Boonen_et_al_2020}, it encourages to tackle hard to operationlize or open-ended tasks \citep{Pollitt_2012a, Pollitt_2012b, Lesterhuis_2018}, and the measurement of competencies \citep{Verhavert_2018}, among others.
